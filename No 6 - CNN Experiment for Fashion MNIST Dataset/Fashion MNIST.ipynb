{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST Data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Class Name\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A : Mean Subtraction and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Pixel Value\n",
      "Train :\n",
      "Min:  0  Max:  255  Mean:  72.94035223214286  Std:  90.02118235130519\n",
      "Test :\n",
      "Min:  0  Max:  255  Mean:  73.14656658163265  Std:  89.87325907809718\n"
     ]
    }
   ],
   "source": [
    "# Pixel values\n",
    "train_min = train_images.min()\n",
    "test_min = test_images.min()\n",
    "\n",
    "train_max = train_images.max()\n",
    "test_max = test_images.max()\n",
    "\n",
    "train_mean = train_images.mean()\n",
    "test_mean = test_images.mean()\n",
    "\n",
    "train_std = train_images.std()\n",
    "test_std = test_images.std()\n",
    "\n",
    "print('Original Pixel Value')\n",
    "print('Train :\\nMin: ', train_min, \" Max: \", train_max, \" Mean: \", train_mean, \" Std: \", train_std)\n",
    "print('Test :\\nMin: ', test_min, \" Max: \", test_max, \" Mean: \", test_mean, \" Std: \", test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Subtraction\n",
    "train_images = train_images - train_mean\n",
    "test_images = test_images - test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_images = train_images / train_std\n",
    "test_images = test_images / test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Pixel Value\n",
      "Train :\n",
      "Min:  -0.8102576563313192  Max:  2.0224089821146136  Mean:  -1.74808013869143e-17  Std:  1.0\n",
      "Test :\n",
      "Min:  -0.81388576904806  Max:  2.023443183031141  Mean:  -5.314569646042382e-17  Std:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Pixel values\n",
    "print('New Pixel Value')\n",
    "print('Train :\\nMin: ', train_images.min(), \" Max: \" ,train_images.max(), \" Mean: \" ,train_images.mean(), \" Std: \" ,train_images.std())\n",
    "print('Test :\\nMin: ', test_images.min(), \" Max: \" ,test_images.max(), \" Mean: \" ,test_images.mean(), \" Std: \" ,test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B : Xavier and He Initalization Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xavier Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4553 - acc: 0.8352\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3512 - acc: 0.8700\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3172 - acc: 0.8823\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2939 - acc: 0.8912\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2763 - acc: 0.8971\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2609 - acc: 0.9031\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2471 - acc: 0.9077\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2376 - acc: 0.9106\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2270 - acc: 0.9156\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2182 - acc: 0.9170\n",
      "10000/10000 - 0s - loss: 0.3589 - acc: 0.8812\n",
      "\n",
      "Test accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.7891 - acc: 0.6905\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.6588 - acc: 0.7578\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 272us/sample - loss: 0.6117 - acc: 0.7866\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 275us/sample - loss: 0.5677 - acc: 0.8055\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 270us/sample - loss: 0.5541 - acc: 0.8094\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 272us/sample - loss: 0.7014 - acc: 0.7478\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 270us/sample - loss: 0.6488 - acc: 0.7696\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 281us/sample - loss: 0.6938 - acc: 0.7673\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 22s 374us/sample - loss: 0.6187 - acc: 0.7801\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.7520 - acc: 0.7278\n",
      "10000/10000 - 1s - loss: 0.8014 - acc: 0.7081\n",
      "\n",
      "Test accuracy: 0.7081\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.4697 - acc: 0.8330 - loss: 0.4710 \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 648us/sample - loss: 0.3583 - acc: 0.8688 - loss: 0.3581 - acc: 0.86\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.3209 - acc: 0.8825\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 39s 643us/sample - loss: 0.2930 - acc: 0.8915\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.2715 - acc: 0.8996\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 39s 652us/sample - loss: 0.2574 - acc: 0.9046\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.2490 - acc: 0.9076\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 652us/sample - loss: 0.2312 - acc: 0.9150\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 648us/sample - loss: 0.2168 - acc: 0.9182\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 649us/sample - loss: 0.2091 - acc: 0.9223\n",
      "10000/10000 - 2s - loss: 0.3901 - acc: 0.8799\n",
      "\n",
      "Test accuracy: 0.8799\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**He Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4530 - acc: 0.8360\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3496 - acc: 0.8726\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3190 - acc: 0.8835\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2942 - acc: 0.8925\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2787 - acc: 0.8953\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2638 - acc: 0.9019\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2515 - acc: 0.9057\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2396 - acc: 0.9093\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2288 - acc: 0.9137\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2209 - acc: 0.9175\n",
      "10000/10000 - 0s - loss: 0.3578 - acc: 0.8824\n",
      "\n",
      "Test accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 19s 309us/sample - loss: 0.6695 - acc: 0.7608\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 18s 294us/sample - loss: 0.5148 - acc: 0.8226\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.4975 - acc: 0.8315\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s 335us/sample - loss: 0.4515 - acc: 0.8460\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s 332us/sample - loss: 0.4459 - acc: 0.8494\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.4399 - acc: 0.8486\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 301us/sample - loss: 0.4562 - acc: 0.8432\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.4113 - acc: 0.8579\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.4235 - acc: 0.8564\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.4268 - acc: 0.8532\n",
      "10000/10000 - 1s - loss: 0.4830 - acc: 0.8384\n",
      "\n",
      "Test accuracy: 0.8384\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 39s 651us/sample - loss: 0.4808 - acc: 0.8339 - loss: 0.\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.3593 - acc: 0.8693\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 650us/sample - loss: 0.3220 - acc: 0.8826 - \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.2938 - acc: 0.8934\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 39s 646us/sample - loss: 0.2723 - acc: 0.9012\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 39s 649us/sample - loss: 0.2529 - acc: 0.9060\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 648us/sample - loss: 0.2460 - acc: 0.9109\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 646us/sample - loss: 0.2314 - acc: 0.9152\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 649us/sample - loss: 0.2163 - acc: 0.9186\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 651us/sample - loss: 0.2038 - acc: 0.9239\n",
      "10000/10000 - 2s - loss: 0.3632 - acc: 0.8829\n",
      "\n",
      "Test accuracy: 0.8829\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C : Network Configuration Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Model** : Normal Implementation for Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.4585 - acc: 0.8340\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3516 - acc: 0.8710\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3192 - acc: 0.8821\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2965 - acc: 0.8895\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2801 - acc: 0.8956\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2637 - acc: 0.9010\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2508 - acc: 0.9051\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2386 - acc: 0.910 - 5s 85us/sample - loss: 0.2386 - acc: 0.9101\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2295 - acc: 0.9151\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2200 - acc: 0.9165\n",
      "10000/10000 - 0s - loss: 0.3661 - acc: 0.8807\n",
      "\n",
      "Test accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Model** : Large Number of Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 415,498\n",
      "Trainable params: 415,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 0.7746 - acc: 0.7010\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.6523 - acc: 0.765 - 17s 283us/sample - loss: 0.6522 - acc: 0.7652\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.5915 - acc: 0.7881\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.5839 - acc: 0.7943\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.6083 - acc: 0.7911\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.7232 - acc: 0.7324\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.6819 - acc: 0.7413\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.7945 - acc: 0.7351\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.9073 - acc: 0.6762\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 271us/sample - loss: 0.6295 - acc: 0.7875\n",
      "10000/10000 - 1s - loss: 0.5839 - acc: 0.8011\n",
      "\n",
      "Test accuracy: 0.8011\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third Model** : Large number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2560)              2009600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 2,035,210\n",
      "Trainable params: 2,035,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 40s 674us/sample - loss: 0.4660 - acc: 0.8353\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 40s 659us/sample - loss: 0.3575 - acc: 0.8691\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 40s 675us/sample - loss: 0.3170 - acc: 0.8826\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 42s 703us/sample - loss: 0.2913 - acc: 0.8939\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 42s 702us/sample - loss: 0.2765 - acc: 0.8999\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 42s 694us/sample - loss: 0.2599 - acc: 0.9040\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 42s 693us/sample - loss: 0.2406 - acc: 0.9117\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 43s 711us/sample - loss: 0.2302 - acc: 0.9147 - loss: 0.2303 - \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 40s 668us/sample - loss: 0.2165 - acc: 0.9189\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 40s 667us/sample - loss: 0.2077 - acc: 0.9217\n",
      "10000/10000 - 2s - loss: 0.3722 - acc: 0.8837\n",
      "\n",
      "Test accuracy: 0.8837\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task D : Gradient Optimization Techniques Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4571 - acc: 0.8344\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3533 - acc: 0.8706\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3190 - acc: 0.8827\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2971 - acc: 0.8893\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2808 - acc: 0.8953\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2660 - acc: 0.9004\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2521 - acc: 0.9068\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2402 - acc: 0.9097\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2305 - acc: 0.9126\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2199 - acc: 0.9169\n",
      "10000/10000 - 0s - loss: 0.3563 - acc: 0.8816\n",
      "\n",
      "Test accuracy: 0.8816\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 21s 352us/sample - loss: 0.8052 - acc: 0.6731\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 316us/sample - loss: 0.6068 - acc: 0.7756\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 304us/sample - loss: 0.6537 - acc: 0.7657\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.6879 - acc: 0.7448\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.6503 - acc: 0.7636\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.6023 - acc: 0.7840\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 299us/sample - loss: 0.5479 - acc: 0.8065\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.6696 - acc: 0.7504\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.8389 - acc: 0.6922\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 300us/sample - loss: 0.6431 - acc: 0.7839\n",
      "10000/10000 - 1s - loss: 0.8384 - acc: 0.7330\n",
      "\n",
      "Test accuracy: 0.733\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 39s 658us/sample - loss: 0.4679 - acc: 0.8334\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 652us/sample - loss: 0.3557 - acc: 0.8701\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 654us/sample - loss: 0.3187 - acc: 0.8829\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 39s 656us/sample - loss: 0.2958 - acc: 0.8918\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.2758 - acc: 0.8983\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.2688 - acc: 0.9026\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.2439 - acc: 0.9092- ETA: 1s -\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 648us/sample - loss: 0.2321 - acc: 0.9143\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 652us/sample - loss: 0.2207 - acc: 0.9175\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.2090 - acc: 0.9224\n",
      "10000/10000 - 2s - loss: 0.3701 - acc: 0.8821\n",
      "\n",
      "Test accuracy: 0.8821\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSprop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.4709 - acc: 0.8294\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3685 - acc: 0.8689\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3395 - acc: 0.8796\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3205 - acc: 0.8876\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3050 - acc: 0.8933\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2992 - acc: 0.8989\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2886 - acc: 0.9027\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2786 - acc: 0.9054\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2749 - acc: 0.9087\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2681 - acc: 0.9101\n",
      "10000/10000 - 0s - loss: 0.4995 - acc: 0.8741\n",
      "\n",
      "Test accuracy: 0.8741\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 23s 388us/sample - loss: 0.8210 - acc: 0.6881\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.5878 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 23s 390us/sample - loss: 0.5562 - acc: 0.8147\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.5344 - acc: 0.8282\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 352us/sample - loss: 0.5590 - acc: 0.8251\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 354us/sample - loss: 0.6365 - acc: 0.8235\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.7053 - acc: 0.8235\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 20s 327us/sample - loss: 0.7019 - acc: 0.8124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 21s 351us/sample - loss: 0.7213 - acc: 0.7958 - loss: 0.7267 - \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 21s 353us/sample - loss: 0.7089 - acc: 0.7902 - \n",
      "10000/10000 - 1s - loss: 0.8409 - acc: 0.7560\n",
      "\n",
      "Test accuracy: 0.756\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.5332 - acc: 0.8241\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.4056 - acc: 0.8686\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.3815 - acc: 0.8776\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.3632 - acc: 0.8863\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.3532 - acc: 0.8934\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.3399 - acc: 0.8997\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.3348 - acc: 0.9035\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 68s 1ms/sample - loss: 0.3217 - acc: 0.9074\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 68s 1ms/sample - loss: 0.3145 - acc: 0.9126\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.3081 - acc: 0.9162\n",
      "10000/10000 - 2s - loss: 0.6299 - acc: 0.8853\n",
      "\n",
      "Test accuracy: 0.8853\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task E : Activation Functions Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.4553 - acc: 0.8350\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3501 - acc: 0.8702\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3189 - acc: 0.8817\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2967 - acc: 0.8898\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2769 - acc: 0.8958\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2620 - acc: 0.9022\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2481 - acc: 0.9070\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2363 - acc: 0.9119\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2305 - acc: 0.9134\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2183 - acc: 0.9176\n",
      "10000/10000 - 0s - loss: 0.3678 - acc: 0.8810\n",
      "\n",
      "Test accuracy: 0.881\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 307us/sample - loss: 0.8847 - acc: 0.6454\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 18s 306us/sample - loss: 0.6630 - acc: 0.7537\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 0.6322 - acc: 0.7728\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.8217 - acc: 0.6985\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 292us/sample - loss: 0.8124 - acc: 0.6945\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.8387 - acc: 0.7256\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 307us/sample - loss: 0.6958 - acc: 0.7751\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 20s 337us/sample - loss: 0.7439 - acc: 0.7399\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 308us/sample - loss: 0.7510 - acc: 0.7246\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 20s 340us/sample - loss: 0.7202 - acc: 0.7393\n",
      "10000/10000 - 1s - loss: 0.7552 - acc: 0.7408\n",
      "\n",
      "Test accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 43s 710us/sample - loss: 0.4656 - acc: 0.8339\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 44s 730us/sample - loss: 0.3581 - acc: 0.8705 -\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 41s 690us/sample - loss: 0.3208 - acc: 0.8840\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 42s 699us/sample - loss: 0.2933 - acc: 0.8921 - los\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 44s 732us/sample - loss: 0.2725 - acc: 0.9005\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 44s 733us/sample - loss: 0.2597 - acc: 0.9054\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 46s 759us/sample - loss: 0.2394 - acc: 0.9106\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 51s 857us/sample - loss: 0.2338 - acc: 0.9142\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 657us/sample - loss: 0.2162 - acc: 0.9197\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 41s 676us/sample - loss: 0.2089 - acc: 0.9219 - loss: 0.2079 -\n",
      "10000/10000 - 2s - loss: 0.4045 - acc: 0.8746\n",
      "\n",
      "Test accuracy: 0.8746\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leaky ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4915 - acc: 0.8259\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3967 - acc: 0.8570\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3609 - acc: 0.8689\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3410 - acc: 0.8742\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3266 - acc: 0.8800\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3154 - acc: 0.8830\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3013 - acc: 0.8882\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2952 - acc: 0.8907\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2884 - acc: 0.8934\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2818 - acc: 0.8962\n",
      "10000/10000 - 1s - loss: 0.3546 - acc: 0.8741\n",
      "\n",
      "Test accuracy: 0.8741\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 23s 392us/sample - loss: 0.7574 - acc: 0.7083\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 20s 335us/sample - loss: 0.5930 - acc: 0.8031\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 20s 334us/sample - loss: 0.4790 - acc: 0.8374\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s 330us/sample - loss: 0.4610 - acc: 0.8453\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s 329us/sample - loss: 0.4468 - acc: 0.8503\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.4815 - acc: 0.8415\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s 367us/sample - loss: 0.4561 - acc: 0.8490 - loss:\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 371us/sample - loss: 0.4025 - acc: 0.8656\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 379us/sample - loss: 0.4319 - acc: 0.8571\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.3721 - acc: 0.8752\n",
      "10000/10000 - 1s - loss: 0.4685 - acc: 0.8481\n",
      "\n",
      "Test accuracy: 0.8481\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 49s 814us/sample - loss: 0.5696 - acc: 0.8134\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 48s 798us/sample - loss: 0.4690 - acc: 0.8398\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 47s 782us/sample - loss: 0.4431 - acc: 0.8493\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 46s 773us/sample - loss: 0.4154 - acc: 0.8590\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 47s 789us/sample - loss: 0.3976 - acc: 0.8654 - loss: - ETA: 3s - loss: 0 - ETA\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 47s 777us/sample - loss: 0.3840 - acc: 0.8703\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 46s 773us/sample - loss: 0.3876 - acc: 0.8707\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 46s 760us/sample - loss: 0.3656 - acc: 0.8759\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 45s 748us/sample - loss: 0.3611 - acc: 0.8787\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 45s 746us/sample - loss: 0.3542 - acc: 0.8814\n",
      "10000/10000 - 2s - loss: 0.4572 - acc: 0.8570\n",
      "\n",
      "Test accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(2560))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task F : Regularization Techniques Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.5996 - acc: 0.7862\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.4760 - acc: 0.8282\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 92us/sample - loss: 0.4487 - acc: 0.8359\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.4302 - acc: 0.8432\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4180 - acc: 0.8485\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4062 - acc: 0.8516\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3990 - acc: 0.8547\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3933 - acc: 0.8559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3850 - acc: 0.8591\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3791 - acc: 0.8600\n",
      "10000/10000 - 0s - loss: 0.3728 - acc: 0.8669\n",
      "\n",
      "Test accuracy: 0.8669\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 1.7483 - acc: 0.2510\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 272us/sample - loss: 1.5079 - acc: 0.3359\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 15s 256us/sample - loss: 1.4643 - acc: 0.3529\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 277us/sample - loss: 1.4483 - acc: 0.3600\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 1.4440 - acc: 0.3633\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 1.4309 - acc: 0.3688\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 1.4238 - acc: 0.3719\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 1.4298 - acc: 0.3690\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 1.4239 - acc: 0.3728\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 1.4246 - acc: 0.3713\n",
      "10000/10000 - 1s - loss: 2.5535 - acc: 0.1054\n",
      "\n",
      "Test accuracy: 0.1054\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 27s 452us/sample - loss: 0.5612 - acc: 0.8043\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 0.4540 - acc: 0.8371\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 28s 468us/sample - loss: 0.4261 - acc: 0.8472\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 0.4106 - acc: 0.8536\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 27s 455us/sample - loss: 0.3943 - acc: 0.8595\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.3836 - acc: 0.8621 - loss: 0\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 25s 412us/sample - loss: 0.3742 - acc: 0.8661\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 0.3645 - acc: 0.8697\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 404us/sample - loss: 0.3595 - acc: 0.8723\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 25s 410us/sample - loss: 0.3574 - acc: 0.8739\n",
      "10000/10000 - 1s - loss: 0.3618 - acc: 0.8759\n",
      "\n",
      "Test accuracy: 0.8759\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(1280, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.6529 - acc: 0.8323\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4985 - acc: 0.8625\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4592 - acc: 0.8707\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4364 - acc: 0.8781\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4231 - acc: 0.8798\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4127 - acc: 0.8818\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.4012 - acc: 0.8855\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3949 - acc: 0.8881\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3892 - acc: 0.8891\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3841 - acc: 0.8908\n",
      "10000/10000 - 0s - loss: 0.5191 - acc: 0.8510\n",
      "\n",
      "Test accuracy: 0.851\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s 199us/sample - loss: 2.3070 - acc: 0.0995\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 193us/sample - loss: 2.3028 - acc: 0.0970\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 2.3028 - acc: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 193us/sample - loss: 2.3028 - acc: 0.0983\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 2.3028 - acc: 0.0988\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 197us/sample - loss: 2.3028 - acc: 0.0979\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 194us/sample - loss: 2.3028 - acc: 0.0994\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 189us/sample - loss: 2.3028 - acc: 0.0980\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 2.3028 - acc: 0.0990\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 2.3028 - acc: 0.0988\n",
      "10000/10000 - 1s - loss: 2.3027 - acc: 0.1000\n",
      "\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 0.6721 - acc: 0.8350\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 383us/sample - loss: 0.4896 - acc: 0.8641\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.4519 - acc: 0.8738\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 382us/sample - loss: 0.4302 - acc: 0.8783\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.4172 - acc: 0.8814\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.4050 - acc: 0.8851\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s 371us/sample - loss: 0.3971 - acc: 0.8864\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 364us/sample - loss: 0.3899 - acc: 0.8883\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.3826 - acc: 0.8895\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 21s 350us/sample - loss: 0.3762 - acc: 0.8917\n",
      "10000/10000 - 1s - loss: 0.5067 - acc: 0.8482\n",
      "\n",
      "Test accuracy: 0.8482\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(1280, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
